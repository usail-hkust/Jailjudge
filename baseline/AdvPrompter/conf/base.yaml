defaults:
  - prompter: llama2  # one of: llama2, tiny_llama (see corresponding .yaml in conf/prompter/)
  - target_llm: vicuna_chat  # one of: llama2_chat, vicuna_chat, mistral_chat, pythia_chat, falcon_chat, gemma_chat, tiny_llama_chat (see corresponding .yaml in conf/target_llm/)
  - _self_
  
verbose: false
seed: 2023
reweight_loss: true
output_dir: "./exp/local/${now:%Y.%m.%d}/${now:%H%M}"

data:
  data_dir: "./data"
  test_prefixes_pth: "${data.data_dir}/test_prefixes.csv"
  affirmative_prefixes_pth: "${data.data_dir}/affirmative_prefixes.csv"

wandb_params:
  entity: "YOUR_WANDB_ENTITY"
  project: "YOUR_WANDB_PROJECT"
  log_sequences_every: 
    train: 1000
    eval: 1000
  enable_wandb: false

hydra:
  run:
    dir: ${output_dir}
  # sweep:
  #   dir: ./exp/${now:%Y.%m.%d}/${hydra.runtime.choices.data}_${now:%H%M}
  #   subdir: ${hydra.job.num}